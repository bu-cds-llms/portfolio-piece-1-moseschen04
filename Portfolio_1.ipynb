{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtrAJQzHLZSD",
        "outputId": "a145255c-9e16-4698-c5a5-00b45276fb90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# SETUP: Run this cell first\n",
        "!pip install gensim scikit-learn numpy matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained Word2Vec embeddings (this may take 1-2 minutes)\n",
        "print(\"Loading pre-trained embeddings...\")\n",
        "word_vectors = api.load('word2vec-google-news-300')\n",
        "print(f\"Loaded! Vocabulary size: {len(word_vectors)} words\")\n",
        "print(f\"Each word is represented by a vector of {word_vectors.vector_size} numbers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUB28_LATLOx",
        "outputId": "d6f76b34-03f8-4339-9599-277770190f88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained embeddings...\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Loaded! Vocabulary size: 3000000 words\n",
            "Each word is represented by a vector of 300 numbers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Service Chatbot using Word2Vec"
      ],
      "metadata": {
        "id": "_M1dzQy-EmEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YErbZ-BCjGd",
        "outputId": "79b98589-e587-4a37-bedc-6ab378d2d722"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\"\n",
        ")\n",
        "\n",
        "def clean(text):\n",
        "    #Cleaning text by lowercasing, splitting, and removing non-lowercase and number characters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9 ]\", \"\", text)\n",
        "    return text.split()\n",
        "\n",
        "#Clean and tokenize instruction sentences\n",
        "df[\"tokens\"] = df[\"instruction\"].apply(clean)"
      ],
      "metadata": {
        "id": "G6gpcsEmCZ68"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split into training and testing datasets to prevent data leakage and overfitting\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Szri_4LHLfgn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "#Initialize model, vector size set to 100 to capture nuanced semantic meaning without overfitting\n",
        "#Set window to 5 because typical queries are short and repetitive\n",
        "#min_count set to 2, so that unique word that appear less than 2 times are removed\n",
        "#workers is simply cpu amount usage\n",
        "model = Word2Vec(\n",
        "    sentences=train_df[\"tokens\"],\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "NHgiEySrEBFg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sentence_vector(tokens):\n",
        "    #Check if each token exists within Word2Vec, and retrieve its embedding\n",
        "    vectors = [\n",
        "        model.wv[word]\n",
        "        for word in tokens\n",
        "        if word in model.wv\n",
        "    ]\n",
        "    #Non matches have no value, prevents breaking\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(100)\n",
        "\n",
        "    return np.mean(vectors, axis=0)"
      ],
      "metadata": {
        "id": "fqmNjOgdELKR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"vec\"] = train_df[\"tokens\"].apply(sentence_vector)\n",
        "test_df[\"vec\"]  = test_df[\"tokens\"].apply(sentence_vector)\n",
        "\n",
        "X_train = np.vstack(train_df[\"vec\"].values)\n",
        "X_test  = np.vstack(test_df[\"vec\"].values)"
      ],
      "metadata": {
        "id": "ngMfZJM3ENlf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Order number extraction & standardization\n",
        "import re\n",
        "\n",
        "def extract_order_number(text):\n",
        "\n",
        "    matches = re.findall(r'\\b[A-Z]*\\d+[A-Z0-9]*\\b', text.upper())\n",
        "\n",
        "    if matches:\n",
        "        return matches[0]\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "7M736r2aYiBH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fake order numbers for testing\n",
        "orders = {\n",
        "    \"58219\": {\n",
        "        \"status\": \"Shipped\",\n",
        "        \"delivery\": \"Feb 25\",\n",
        "        \"item\": \"Laptop\",\n",
        "        \"refundable\": False\n",
        "    },\n",
        "    \"ZX00122\": {\n",
        "        \"status\": \"Delivered\",\n",
        "        \"delivery\": \"Feb 20\",\n",
        "        \"item\": \"Headphones\",\n",
        "        \"refundable\": True\n",
        "    },\n",
        "    \"ABX9123\": {\n",
        "        \"status\": \"Processing\",\n",
        "        \"delivery\": \"Feb 27\",\n",
        "        \"item\": \"Monitor\",\n",
        "        \"refundable\": True\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "K_MY5ZHlYo6N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ORDER_REQUIRED_INTENTS = [\n",
        "    \"track_order\",\n",
        "    \"cancel_order\",\n",
        "    \"refund_order\",\n",
        "    \"order_status\",\n",
        "    \"update_address\"\n",
        "]"
      ],
      "metadata": {
        "id": "r912nGwSaF-q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "STOPWORDS = [\"order\"]\n",
        "\n",
        "def predict_intent(user_input):\n",
        "\n",
        "    #Extract order number\n",
        "    order_num = extract_order_number(user_input)\n",
        "\n",
        "    cleaned_input = user_input\n",
        "    if order_num:\n",
        "        cleaned_input = cleaned_input.replace(order_num, \"\")\n",
        "\n",
        "    tokens = [\n",
        "        t for t in clean(cleaned_input)\n",
        "        if t not in STOPWORDS\n",
        "    ]\n",
        "\n",
        "    user_vec = sentence_vector(tokens).reshape(1, -1)\n",
        "\n",
        "    sims = cosine_similarity(user_vec, X_train)\n",
        "    best_match = sims.argmax()\n",
        "\n",
        "    return train_df.iloc[best_match][\"intent\"]"
      ],
      "metadata": {
        "id": "LDKEKBD7EPf4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_intent(\"cancel order 58219\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lyrr3FtyERAf",
        "outputId": "6bbf38ed-35a2-45af-8ba5-aa2984ccc428"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cancel_order'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for i, row in test_df.iterrows():\n",
        "\n",
        "    #rebuild sentence from tokens\n",
        "    test_sentence = \" \".join(row[\"tokens\"])\n",
        "\n",
        "    pred = predict_intent(test_sentence)\n",
        "\n",
        "    y_true.append(row[\"intent\"])\n",
        "    y_pred.append(pred)"
      ],
      "metadata": {
        "id": "EwwR-pmVKdjR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(\"Intent Classification Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mRr-j0hPdLx",
        "outputId": "625b95c5-3022-4c23-9006-87fe547e43a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent Classification Accuracy: 0.9484651162790698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(user_input):\n",
        "\n",
        "    order_num = extract_order_number(user_input)\n",
        "\n",
        "    #Predict intent\n",
        "    intent = predict_intent(user_input)\n",
        "\n",
        "    #Retrieve reponse\n",
        "    response = train_df[\n",
        "        train_df[\"intent\"] == intent\n",
        "    ].iloc[0][\"response\"]\n",
        "\n",
        "    if intent in ORDER_REQUIRED_INTENTS:\n",
        "\n",
        "        if not order_num:\n",
        "            return \"Please provide your order number so I can assist you.\"\n",
        "\n",
        "        if order_num not in orders:\n",
        "            return f\"I couldn't find order {order_num}. Please double check it.\"\n",
        "\n",
        "        order = orders[order_num]\n",
        "\n",
        "        if intent == \"track_order\":\n",
        "            return f\"Order {order_num} is currently {order['status']} and expected by {order['delivery']}.\"\n",
        "\n",
        "        if intent == \"cancel_order\":\n",
        "            if order[\"status\"] == \"Shipped\":\n",
        "                return f\"Order {order_num} has already shipped and cannot be cancelled.\"\n",
        "            else:\n",
        "                return f\"Order {order_num} has been cancelled successfully.\"\n",
        "\n",
        "        if intent == \"refund_order\":\n",
        "            if not order[\"refundable\"]:\n",
        "                return f\"Order {order_num} is not eligible for refund.\"\n",
        "            else:\n",
        "                return f\"Refund for order {order_num} has been initiated.\"\n",
        "\n",
        "        if intent == \"order_status\":\n",
        "            return f\"Order {order_num} contains a {order['item']} and is currently {order['status']}.\"\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "XNOkfhbdPvr4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot('cancel order 58219')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tkzgJn0rQMhu",
        "outputId": "08c985c2-8b0e-4e54-da32-3479578224bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Order 58219 has already shipped and cannot be cancelled.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}